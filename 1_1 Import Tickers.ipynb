{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The aim of this module is to extract data from yahood finance and export to pipe delimitered CSV files\n",
    "\n",
    "# Exports are:\n",
    "# R_ALL_TICKER >> list of all tickers in scope\n",
    "# R_ALL_INFO >> point in time information\n",
    "# R_ALL_FIN >> financial information, balance sheet, income statement and cashflow\n",
    "# R_ALL_Prices >> historical prices over last x months\n",
    "# R_ALL_Div >> dividend price over time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# File name convention\n",
    "# R_ = raw extract \n",
    "# E_ = Entry files into enrichment layer\n",
    "# C_ = enriched layer with calculation\n",
    "# I = insights layer, designed for model baselines\n",
    "# V_ = validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASX Tickers\n",
    "RAW_TICKER_ASX = pd.read_csv('https://www.asx.com.au/asx/research/ASXListedCompanies.csv',skiprows=1)\n",
    "RAW_TICKER_ASX[\"Ticker\"] = RAW_TICKER_ASX['ASX code']+\".AX\"\n",
    "TICKER_ASX = list(RAW_TICKER_ASX['Ticker'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nasdaq Tickers\n",
    "#ftp.nasdaqtrader.com/SymbolDirectory/nasdaqlisted.txt\n",
    "#ftp.nasdaqtrader.com/SymbolDirectory/otherlisted.txt\n",
    "\n",
    "RAW_TICKER_NDQ = pd.read_csv('/Users/joezhou/Downloads/nasdaqlisted.txt',sep=\"|\")\n",
    "RAW_TICKER_NDQ[\"Ticker\"] = RAW_TICKER_NDQ['Symbol']\n",
    "TICKER_NDQ = list(RAW_TICKER_NDQ['Ticker'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#London Stock Exchange Tickers\n",
    "RAW_TICKER_LSE = pd.read_excel (r'https://docs.londonstockexchange.com/sites/default/files/documents/list_of_sets_securities_14.xls', sheet_name='SETS',skiprows=3)\n",
    "RAW_TICKER_LSE[\"Ticker\"] = RAW_TICKER_LSE['Mnemonic']+\".L\"\n",
    "TICKER_LSE = list(RAW_TICKER_LSE['Ticker'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NYSE Tickers\n",
    "# RAW_TICKER_NYSE = pd.read_excel (r'https://www.theice.com/publicdocs/data/NYSE_Equity_Index_Ticker_List.xlsx', sheet_name='SETS',skiprows=3)\n",
    "\n",
    "#Note: Need to find a better data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append list for data extraction layer\n",
    "TICKER_ALL = TICKER_ASX\n",
    "# TICKER_ALL = (TICKER_ASX + TICKER_NDQ + TICKER_LSE)\n",
    "\n",
    "TICKER_ALL.sort()\n",
    "four_split = np.array_split(TICKER_ALL, 4)\n",
    "\n",
    "TICKER_ALL_1 = four_split[0]\n",
    "TICKER_ALL_2 = four_split[1]\n",
    "TICKER_ALL_3 = four_split[2]\n",
    "TICKER_ALL_4 = four_split[3]\n",
    "\n",
    "#Remove Duplicates\n",
    "# TICKER_ALL = list(dict.fromkeys(TICKER_ALL))\n",
    "\n",
    "\n",
    "# Export all ticker list for referencing purposes\n",
    "df_x = pd.DataFrame(TICKER_ALL, columns=[\"colummn\"])\n",
    "df_x.to_pickle(\"/Users/joezhou/Downloads/R_ALL_TICKER.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample top 5 for testing code purposes\n",
    "# TICKER_ASXs = TICKER_ASX[:5]\n",
    "# TICKER_NDQs = TICKER_NDQ[:5]\n",
    "# TICKER_LSEs = TICKER_LSE[:5]\n",
    "\n",
    "# TICKER_ALL = (TICKER_ASXs + TICKER_NDQs + TICKER_LSEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download part 1: Company Information\n",
    "\n",
    "INF_DF = pd.DataFrame()\n",
    "\n",
    "def Info_Extract(TickName):    \n",
    "    global INF_DF\n",
    "    try:\n",
    "        tick = yf.Ticker(TickName) \n",
    "        INF = tick.info\n",
    "        INF_DF = INF_DF.append(INF, ignore_index=True) \n",
    "         \n",
    "        print(\"finished Info:\",TickName)\n",
    "        \n",
    "    except Exception:\n",
    "        print(\"Error with Info:\",TickName)\n",
    "        pass\n",
    "    \n",
    "    return()\n",
    "\n",
    "# Download all\n",
    "# for company in TICKER_ALL:\n",
    "#    Info_Extract(company)\n",
    "\n",
    "\n",
    "# download partial\n",
    "# for company in TICKER_ALL_1:\n",
    "#    Info_Extract(company)\n",
    "# INF_DF_1 = INF_DF\n",
    "\n",
    "# for company in TICKER_ALL_2:\n",
    "#    Info_Extract(company)\n",
    "# INF_DF_2 = INF_DF\n",
    "\n",
    "# for company in TICKER_ALL_3:\n",
    "#    Info_Extract(company)\n",
    "# INF_DF_3 = INF_DF\n",
    "\n",
    "# for company in TICKER_ALL_4:\n",
    "#    Info_Extract(company)\n",
    "# INF_DF_4 = INF_DF\n",
    "\n",
    "# INF_DF_Master = pd.concat([INF_DF_1, INF_DF_2, INF_DF_3, INF_DF_4], ignore_index=True)\n",
    "\n",
    "# for company in TICKER_ALL:\n",
    "    # Info_Extract(company)\n",
    "# INF_DF.to_pickle(\"/Users/joezhou/Downloads/R_ALL_INFO.pkl\")\n",
    "\n",
    "# INF_DF_1.to_pickle(\"/Users/joezhou/Downloads/R_ALL_INFO_1.pkl\")\n",
    "# INF_DF_2.to_pickle(\"/Users/joezhou/Downloads/R_ALL_INFO_2.pkl\")\n",
    "# INF_DF_3.to_pickle(\"/Users/joezhou/Downloads/R_ALL_INFO_3.pkl\")\n",
    "# INF_DF_4.to_pickle(\"/Users/joezhou/Downloads/R_ALL_INFO_4.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Download part 2: financial data\n",
    "\n",
    "FINANCIALS_DF = pd.DataFrame()\n",
    "\n",
    "def Financials_Extract(TickName):\n",
    "    global FINANCIALS_DF\n",
    "    try:\n",
    "        tick = yf.Ticker(TickName) \n",
    "        \n",
    "        #income statement\n",
    "        FIN_OG = tick.financials\n",
    "        FIN_OG2 = FIN_OG.reset_index()\n",
    "        FIN_OG2.rename(columns = {'index':'Metric'}, inplace = True)\n",
    "        FIN_OG3=FIN_OG2.melt(id_vars=[\"Metric\"],var_name=\"Date\",value_name=\"Value\")\n",
    "        FIN_OG3['TickName']=TickName\n",
    "        FIN_OG3['Financial Data Type']=\"Income Statement\"\n",
    "        \n",
    "        FINANCIALS_DF = FINANCIALS_DF.append(FIN_OG3, ignore_index=True)\n",
    "         \n",
    "        #balance sheet\n",
    "        BS_OG = tick.balance_sheet\n",
    "        BS_OG2 = BS_OG.reset_index()\n",
    "        BS_OG2.rename(columns = {'index':'Metric'}, inplace = True)\n",
    "        BS_OG3=BS_OG2.melt(id_vars=[\"Metric\"],var_name=\"Date\",value_name=\"Value\")\n",
    "        BS_OG3['TickName']=TickName\n",
    "        BS_OG3['Financial Data Type']=\"Balance Sheet\"\n",
    "        \n",
    "        FINANCIALS_DF = FINANCIALS_DF.append(BS_OG3, ignore_index=True)\n",
    "        \n",
    "        #cashflow\n",
    "        CF_OG = tick.cashflow\n",
    "        CF_OG2 = CF_OG.reset_index()\n",
    "        CF_OG2.rename(columns = {'index':'Metric'}, inplace = True)\n",
    "        CF_OG3=CF_OG2.melt(id_vars=[\"Metric\"],var_name=\"Date\",value_name=\"Value\")\n",
    "        CF_OG3['TickName']=TickName\n",
    "        CF_OG3['Financial Data Type']=\"Cashflow\"\n",
    "        \n",
    "        FINANCIALS_DF = FINANCIALS_DF.append(CF_OG3, ignore_index=True)\n",
    "        \n",
    "            \n",
    "        print(\"finished Financial:\",TickName)\n",
    "        \n",
    "    except Exception:\n",
    "        print(\"Error with Financial:\",TickName)\n",
    "        pass\n",
    "\n",
    "    return()\n",
    "\n",
    "# download all at once\n",
    "# for company in TICKER_ALL:\n",
    "#    Financials_Extract(company)\n",
    "\n",
    "\n",
    "#  download partial\n",
    "# for company in TICKER_ALL_1:\n",
    "#    Financials_Extract(company)\n",
    "# FINANCIALS_DF_1 = FINANCIALS_DF\n",
    "# FINANCIALS_DF_1.to_pickle(\"/Users/joezhou/Downloads/R_ALL_FIN_1.pkl\")\n",
    "\n",
    "for company in TICKER_ALL_2:\n",
    "   Financials_Extract(company)\n",
    "FINANCIALS_DF_2 = FINANCIALS_DF\n",
    "FINANCIALS_DF_2.to_pickle(\"/Users/joezhou/Downloads/R_ALL_FIN_2.pkl\")\n",
    "\n",
    "# for company in TICKER_ALL_3:\n",
    "#    Financials_Extract(company)\n",
    "# FINANCIALS_DF_3 = FINANCIALS_DF\n",
    "# FINANCIALS_DF_3.to_pickle(\"/Users/joezhou/Downloads/R_ALL_FIN_3.pkl\")\n",
    "\n",
    "# for company in TICKER_ALL_4:\n",
    "#    Financials_Extract(company)\n",
    "# FINANCIALS_DF_4 = FINANCIALS_DF\n",
    "# FINANCIALS_DF_4.to_pickle(\"/Users/joezhou/Downloads/R_ALL_FIN_4.pkl\")\n",
    "\n",
    "# INF_DF_Master = pd.concat([FINANCIALS_DF_1, FINANCIALS_DF_2, FINANCIALS_DF_3, FINANCIALS_DF_4], ignore_index=True)\n",
    "\n",
    "# for company in TICKER_ALL:\n",
    "    # Financials_Extract(company)\n",
    "# FINANCIALS_DF.to_csv('/Users/joezhou/Downloads/R_ALL_FIN.csv', sep='|', index=False)\n",
    "# FINANCIALS_DF.to_pickle(\"/Users/joezhou/Downloads/R_ALL_FIN.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINANCIALS_DF_1.to_pickle(\"/Users/joezhou/Downloads/R_ALL_FIN_1.pkl\")\n",
    "# FINANCIALS_DF_3.to_pickle(\"/Users/joezhou/Downloads/R_ALL_FIN_3.pkl\")\n",
    "# FINANCIALS_DF_4.to_pickle(\"/Users/joezhou/Downloads/R_ALL_FIN_4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Download part 3: Download historical share prices\n",
    "HIST_PRICE_DF = pd.DataFrame()\n",
    "\n",
    "def Prices_Extract(TickName):\n",
    "    \n",
    "    global HIST_PRICE_DF\n",
    "\n",
    "    try:\n",
    "        tick = yf.Ticker(TickName) \n",
    "        \n",
    "        hist_p = tick.history(period=\"6mo\")\n",
    "        hist_p2 = hist_p.reset_index()\n",
    "        hist_p2.rename(columns = {'index':'Metric'}, inplace = True)\n",
    "        \n",
    "        hist_p2['TickName']=TickName\n",
    "\n",
    "        HIST_PRICE_DF = HIST_PRICE_DF.append(hist_p2, ignore_index=True)\n",
    "        \n",
    "            \n",
    "        print(\"finished Price:\",TickName)\n",
    "        \n",
    "    except Exception:\n",
    "        print(\"Error with Price:\",TickName)\n",
    "        pass\n",
    "\n",
    "    return()\n",
    "\n",
    "\n",
    "for company in TICKER_ALL:\n",
    "    Prices_Extract(company)\n",
    "\n",
    "# HIST_PRICE_DF.to_csv('/Users/joezhou/Downloads/R_ALL_Prices.csv', sep='|', index=False)\n",
    "HIST_PRICE_DF.to_pickle(\"/Users/joezhou/Downloads/R_ALL_Prices.pkl\")\n",
    "\n",
    "# HIST_PRICE_DF_1.to_csv('/Users/joezhou/Downloads/R_ALL_Prices_1.csv', sep='|', index=False)\n",
    "# HIST_PRICE_DF_2.to_csv('/Users/joezhou/Downloads/R_ALL_Prices_2.csv', sep='|', index=False)\n",
    "# HIST_PRICE_DF_3.to_csv('/Users/joezhou/Downloads/R_ALL_Prices_3.csv', sep='|', index=False)\n",
    "# HIST_PRICE_DF_4.to_csv('/Users/joezhou/Downloads/R_ALL_Prices_4.csv', sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Part 4: historical dividend information\n",
    "\n",
    "#DIV = tick.dividends  \n",
    "\n",
    "\n",
    "HIST_DIV_DF = pd.DataFrame()\n",
    "\n",
    "def Dividend_Extract(TickName):\n",
    "    global HIST_DIV_DF\n",
    "    try:\n",
    "        tick = yf.Ticker(TickName) \n",
    "        \n",
    "        #income statement\n",
    "        DIV_OG = tick.dividends\n",
    "        DIV_OG2 = DIV_OG.reset_index()\n",
    "        DIV_OG2.rename(columns = {'index':'Metric'}, inplace = True)\n",
    "        DIV_OG2['TickName']=TickName\n",
    "        \n",
    "        HIST_DIV_DF = HIST_DIV_DF.append(DIV_OG2, ignore_index=True)\n",
    "        \n",
    "            \n",
    "        print(\"finished Dividend\",TickName)\n",
    "        \n",
    "    except Exception:\n",
    "        print(\"Error with Dividend\",TickName)\n",
    "\n",
    "        pass\n",
    "\n",
    "    return()\n",
    "\n",
    "for company in TICKER_ALL:\n",
    "   Dividend_Extract(company)\n",
    "\n",
    "HIST_DIV_DF.to_csv('/Users/joezhou/Downloads/R_ALL_Div.csv', sep='|', index=False) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inject data into SQL lite database or some kind of clouud database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert data\n",
    "#DF_SHORT.to_sql('test', db_sql, if_exists='replace')\n",
    "\n",
    "#pd.read_sql('select * from test', db_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install yfinance==0.1.62\n",
    "\n",
    "# ticker = yf.Ticker('AAPL')\n",
    "# aapl_df = ticker.history(period=\"1y\")\n",
    "# aapl_df['Close'].plot(title=\"APPLE's stock price\")\n",
    "\n",
    "# aapl_df = yf.download('AAPL', \n",
    "                    #   start='2022-01-01', \n",
    "                    #   end='2022-03-16', \n",
    "                    #   progress=False,\n",
    "# )\n",
    "# aapl_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "29ef60e46f341bb51c2a63b17c19fb7c83213fa52e6b916fbf12c8b5ee03317f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# HIST_PRICE_DF = pd.read_excel (r'/Users/joezhou/Downloads/ALL_Prices.xlsx')\n",
    "HIST_PRICE_DF_RAW = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_Prices.csv', sep='|')\n",
    "\n",
    "#Create a sample for code testing purposes\n",
    "# HIST_PRICE_DF = HIST_PRICE_DF_RAW[HIST_PRICE_DF_RAW['TickName'].isin(['BHP.AX','RIO.AX','TCL.AX','CBA.AX','MQG.AX','CSL.AX','NAB.AX','WBC.AX','SCG.AX','ANZ.AX','FMG.AX','WES.AX','TLS.AX','RMD.AX','WOW.AX','APA.AX','ATM.AX','GMG.AX','STO.AX','AMC.AX','MGR.AX','COL.AX','ALL.AX','NCM.AX','ZIP.AX'])]\n",
    "\n",
    "HIST_PRICE_DF = HIST_PRICE_DF_RAW\n",
    "\n",
    "#create a baselist for adding on the feature engineered variables\n",
    "TICKER_LIST = HIST_PRICE_DF['TickName'].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-b4abf3bd20ec>:18: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  HIST_PRICE_DF_SUM = HIST_PRICE_DF.groupby(\"TickName\")[\"Freq\", \"DAY_UP\",\"DAY_DWN\", \"DAY_FLAT\", \"DAY_CHANGE_NUM\", \"DAY_CHANGE_RATE\"].sum()\n"
     ]
    }
   ],
   "source": [
    "# Create tag variables\n",
    "# Calculated higher or lower\n",
    "# daily change \n",
    "# daily change absolute\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "HIST_PRICE_DF['Freq'] = 1\n",
    "\n",
    "\n",
    "HIST_PRICE_DF['DAY_UP'] = np.where(HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] > 0, 1, 0)\n",
    "HIST_PRICE_DF['DAY_DWN'] = np.where(HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] < 0, 1, 0)\n",
    "HIST_PRICE_DF['DAY_FLAT'] = np.where(HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] == 0, 1, 0)\n",
    "\n",
    "HIST_PRICE_DF['DAY_CHANGE_RATE'] = HIST_PRICE_DF['Close'] / HIST_PRICE_DF['Open'] - 1\n",
    "HIST_PRICE_DF['DAY_CHANGE_NUM'] = HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] \n",
    "\n",
    "HIST_PRICE_DF_SUM = HIST_PRICE_DF.groupby(\"TickName\")[\"Freq\", \"DAY_UP\",\"DAY_DWN\", \"DAY_FLAT\", \"DAY_CHANGE_NUM\", \"DAY_CHANGE_RATE\"].sum()\n",
    "\n",
    "# calculate the magnitude of movement\n",
    "\n",
    "\n",
    "\n",
    "# HIST_PRICE_DF['Mvmt_val'] = HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open']\n",
    "# HIST_PRICE_DF['Mvmt_rate'] = HIST_PRICE_DF['Close'] / HIST_PRICE_DF['Open']-1\n",
    "\n",
    "# tag events\n",
    "\n",
    "# HIST_PRICE_DF.loc[HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] > 0, 'DAY_UP_VAL'] = HIST_PRICE_DF['Mvmt_val']\n",
    "# HIST_PRICE_DF.loc[HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] > 0, 'DAY_UP_RATE'] = HIST_PRICE_DF['Mvmt_rate']\n",
    "\n",
    "# down movements\n",
    "# HIST_PRICE_DF.loc[HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] < 0, 'DAY_DWN_VAL'] = HIST_PRICE_DF['Mvmt_val']\n",
    "# HIST_PRICE_DF.loc[HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] < 0, 'DAY_DWN_RATE'] = HIST_PRICE_DF['Mvmt_rate']\n",
    "\n",
    "# Aggregate to ticker level\n",
    "\n",
    "# HIST_PRICE_DF_SUM = HIST_PRICE_DF.groupby(\"TickName\")[\"DAY_UP\", \"Freq\", \"DAY_UP_VAL\", \"DAY_UP_RATE\" , \"DAY_DWN_VAL\",\"DAY_DWN_RATE\" ].sum()\n",
    "# HIST_PRICE_DF_MED = HIST_PRICE_DF.groupby(\"TickName\")[\"DAY_UP_VAL\", \"DAY_UP_RATE\", \"DAY_DWN_VAL\",\"DAY_DWN_RATE\" ].median()\n",
    "# HIST_PRICE_DF_AVG = HIST_PRICE_DF.groupby(\"TickName\")[\"DAY_UP_VAL\", \"DAY_UP_RATE\", \"DAY_DWN_VAL\",\"DAY_DWN_RATE\" ].mean()\n",
    "\n",
    "\n",
    "# def f(grp):\n",
    "#     return pd.DataFrame({\n",
    "#                 'N_DAYS':len(grp),\n",
    "#                 'N_UP_DAYS': grp['DAY_UP'].sum(),\n",
    "#                 'Percentage of Up days': grp['DAY_UP'].mean(),\n",
    "#                 'Average daily change':grp['DAY_CHANGE_RATE'].mean(),\n",
    "#                 'Median daily change':grp['DAY_CHANGE_RATE'].median(),\n",
    "#                 }\n",
    "                # ,\n",
    "\n",
    "                # 'NEW_VAR': grp['C'].mean() / grp['X'].sum()},  # <--- here we access different columns...\n",
    "                # index=[grp.name]\n",
    "                # )\n",
    "# ## -- End pasted text --\n",
    "\n",
    "# HIST_PRICE_DF_SUM = HIST_PRICE_DF.groupby('TickName', as_index=False).apply(f)\n",
    "\n",
    "\n",
    "HIST_PRICE_DF_FIRST = HIST_PRICE_DF.groupby(\"TickName\").first()\n",
    "HIST_PRICE_DF_LAST = HIST_PRICE_DF.groupby(\"TickName\").last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ticker level file\n",
    "\n",
    "DF_PRICE_INFO = HIST_PRICE_DF_SUM[[\"Freq\", \"DAY_UP\",\"DAY_DWN\", \"DAY_FLAT\"]].merge(HIST_PRICE_DF_FIRST[['Open']], on = 'TickName',how = 'left')\n",
    "DF_PRICE_INFO = DF_PRICE_INFO.merge(HIST_PRICE_DF_LAST[['Close']], on = 'TickName',how = 'left')\n",
    "\n",
    "# calculate at ticker level\n",
    "DF_PRICE_INFO['PROB_HIGH'] = DF_PRICE_INFO['DAY_UP'] / DF_PRICE_INFO['Freq']\n",
    "DF_PRICE_INFO['PROB_DWN'] = DF_PRICE_INFO['DAY_DWN'] / DF_PRICE_INFO['Freq']\n",
    "DF_PRICE_INFO['PROB_FLAT'] = DF_PRICE_INFO['DAY_FLAT'] / DF_PRICE_INFO['Freq']\n",
    "\n",
    "DF_PRICE_INFO['CHG_RTE_PRICE'] = DF_PRICE_INFO['Close'] / DF_PRICE_INFO['Open'] -1\n",
    "\n",
    "del HIST_PRICE_DF_SUM, HIST_PRICE_DF_FIRST, HIST_PRICE_DF_LAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_YFIN_INFO1 = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_INFO_1.csv',sep='|') \n",
    "DF_YFIN_INFO2 = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_INFO_2.csv',sep='|') \n",
    "DF_YFIN_INFO3 = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_INFO_3.csv',sep='|') \n",
    "DF_YFIN_INFO4 = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_INFO_4.csv',sep='|') \n",
    "\n",
    "DF_YFIN_INFO = pd.concat([DF_YFIN_INFO1, DF_YFIN_INFO2, DF_YFIN_INFO3, DF_YFIN_INFO4], ignore_index=True)\n",
    "# DF_YFIN_INFO = pd.concat([DF_YFIN_INFO1, DF_YFIN_INFO2, DF_YFIN_INFO3], ignore_index=True)\n",
    "\n",
    "\n",
    "del DF_YFIN_INFO1, DF_YFIN_INFO2, DF_YFIN_INFO3, DF_YFIN_INFO4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep columns needed, selected after manual review\n",
    "\n",
    "DF_YFIN_INFO_SUBSET = DF_YFIN_INFO[[\n",
    "# Price / volume Movement\t\n",
    "'52WeekChange','fiftyDayAverage','fiftyTwoWeekHigh','fiftyTwoWeekLow','averageDailyVolume10Day','averageVolume10days',\n",
    "#Location\t\n",
    "'address1','address2','city','state','country','zip','exchange',\n",
    "# Dividend\t\n",
    "'dividendRate','dividendYield','exDividendDate','payoutRatio','trailingAnnualDividendRate','trailingAnnualDividendYield',\n",
    "# Timing\t\n",
    "'mostRecentQuarter','lastFiscalYearEnd','lastSplitDate','nextFiscalYearEnd',\n",
    "# Fundamentals\t\n",
    "'open','marketCap','sharesOutstanding','floatShares','bookValue','regularMarketPrice','regularMarketVolume','heldPercentInsiders','heldPercentInstitutions',\n",
    "# Performance\t\n",
    "'earningsQuarterlyGrowth','netIncomeToCommon','beta','enterpriseToEbitda','enterpriseToRevenue','enterpriseValue','priceToBook','priceToSalesTrailing12Months','profitMargins','trailingEps','trailingPE','fullTimeEmployees',\n",
    "# Future dated\t\n",
    "'forwardEps','forwardPE',\n",
    "# Company Identifier\t\n",
    "'symbol','shortName','longName',\n",
    "# ,'longBusinessSummary','website','messageBoardId',\n",
    "# Index Grouping\t\n",
    "'industry','sector'\n",
    "]]\n",
    "\n",
    "DF_YFIN_INFO_SUBSET.rename(columns={\"symbol\": \"TickName\"}, inplace = True)\n",
    "\n",
    "\n",
    "#Create a sample for code testing purposes\n",
    "# DF_YFIN_INFO_SUBSET = DF_YFIN_INFO_SUBSET[DF_YFIN_INFO_SUBSET['TickName'].isin(['BHP.AX','RIO.AX','TCL.AX','CBA.AX','MQG.AX','CSL.AX','NAB.AX','WBC.AX','SCG.AX','ANZ.AX','FMG.AX','WES.AX','TLS.AX','RMD.AX','WOW.AX','APA.AX','ATM.AX','GMG.AX','STO.AX','AMC.AX','MGR.AX','COL.AX','ALL.AX','NCM.AX','ZIP.AX'])]\n",
    "\n",
    "\n",
    "# DF_YFIN_INFO_SUBSET = DF_YFIN_INFO_SUBSET[['TickName', 'sector']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add info onto prices data\n",
    "\n",
    "\n",
    "DF_YFIN_INFO_SUBSET.set_index('TickName')\n",
    "# DF_PRICE_INFO.set_index('TickName')\n",
    "\n",
    "\n",
    "ADDED_PRICE_INF = DF_PRICE_INFO.merge(DF_YFIN_INFO_SUBSET, on = 'TickName',how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sector related models\n",
    "MOD_DATA = ADDED_PRICE_INF[['TickName','PROB_HIGH','CHG_RTE_PRICE','sector']]\n",
    "\n",
    "# padding rows into columns of 1 or 0\n",
    "MOD_DATA = pd.concat([MOD_DATA, pd.get_dummies(MOD_DATA['sector'])], axis=1);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29ef60e46f341bb51c2a63b17c19fb7c83213fa52e6b916fbf12c8b5ee03317f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# HIST_PRICE_DF = pd.read_excel (r'/Users/joezhou/Downloads/ALL_Prices.xlsx')\n",
    "HIST_PRICE_DF_RAW = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_Prices.csv', sep='|')\n",
    "\n",
    "#Create a sample for code testing purposes\n",
    "# HIST_PRICE_DF = HIST_PRICE_DF_RAW[HIST_PRICE_DF_RAW['TickName'].isin(['BHP.AX','RIO.AX','TCL.AX','CBA.AX','MQG.AX','CSL.AX','NAB.AX','WBC.AX','SCG.AX','ANZ.AX','FMG.AX','WES.AX','TLS.AX','RMD.AX','WOW.AX','APA.AX','ATM.AX','GMG.AX','STO.AX','AMC.AX','MGR.AX','COL.AX','ALL.AX','NCM.AX','ZIP.AX'])]\n",
    "\n",
    "HIST_PRICE_DF = HIST_PRICE_DF_RAW\n",
    "\n",
    "#create a baselist for adding on the feature engineered variables\n",
    "TICKER_LIST = HIST_PRICE_DF['TickName'].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-a80d6e694314>:27: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  HIST_PRICE_DF_SUM = HIST_PRICE_DF.groupby(\"TickName\")[\"Freq\", \"DAY_UP\",\"DAY_DWN\", \"DAY_FLAT\", \"DAY_CHANGE_NUM\", \"DAY_CHANGE_RATE\", \"DAYS_ABOVE_LCLSE\", \"DAYS_BELOW_LCLSE\"].sum()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# find ends of the data window\n",
    "HIST_PRICE_DF_FIRST = HIST_PRICE_DF.groupby(\"TickName\").first()\n",
    "HIST_PRICE_DF_FIRST.rename(columns={\"Open\": \"First_Open_price\"}, inplace = True)\n",
    "\n",
    "\n",
    "HIST_PRICE_DF_LAST = HIST_PRICE_DF.groupby(\"TickName\").last()\n",
    "HIST_PRICE_DF_LAST.rename(columns={\"Close\": \"Last_Close_price\"}, inplace = True)\n",
    "HIST_PRICE_DF = HIST_PRICE_DF.merge(HIST_PRICE_DF_LAST[['Last_Close_price']], on = 'TickName',how = 'left')\n",
    "\n",
    "\n",
    "# create calculated columns\n",
    "HIST_PRICE_DF['Freq'] = 1\n",
    "\n",
    "HIST_PRICE_DF['DAY_UP'] = np.where(HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] > 0, 1, 0)\n",
    "HIST_PRICE_DF['DAY_DWN'] = np.where(HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] < 0, 1, 0)\n",
    "HIST_PRICE_DF['DAY_FLAT'] = np.where(HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] == 0, 1, 0)\n",
    "\n",
    "HIST_PRICE_DF['DAY_CHANGE_RATE'] = HIST_PRICE_DF['Close'] / HIST_PRICE_DF['Open'] - 1\n",
    "HIST_PRICE_DF['DAY_CHANGE_NUM'] = HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] \n",
    "\n",
    "HIST_PRICE_DF['DAYS_ABOVE_LCLSE'] = np.where(HIST_PRICE_DF['Last_Close_price'] - HIST_PRICE_DF['Close'] > 0, 1, 0)\n",
    "HIST_PRICE_DF['DAYS_BELOW_LCLSE'] = np.where(HIST_PRICE_DF['Last_Close_price'] - HIST_PRICE_DF['Close'] < 0, 1, 0)\n",
    "\n",
    "# aggregate to ticker level for calcs\n",
    "HIST_PRICE_DF_SUM = HIST_PRICE_DF.groupby(\"TickName\")[\"Freq\", \"DAY_UP\",\"DAY_DWN\", \"DAY_FLAT\", \"DAY_CHANGE_NUM\", \"DAY_CHANGE_RATE\", \"DAYS_ABOVE_LCLSE\", \"DAYS_BELOW_LCLSE\"].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ticker level file\n",
    "\n",
    "DF_PRICE_INFO = HIST_PRICE_DF_SUM[[\"Freq\", \"DAY_UP\",\"DAY_DWN\", \"DAY_FLAT\", \"DAYS_ABOVE_LCLSE\", \"DAYS_BELOW_LCLSE\"]].merge(HIST_PRICE_DF_FIRST[['First_Open_price']], on = 'TickName',how = 'left')\n",
    "DF_PRICE_INFO = DF_PRICE_INFO.merge(HIST_PRICE_DF_LAST[['Last_Close_price']], on = 'TickName',how = 'left')\n",
    "\n",
    "# calculate at ticker level\n",
    "DF_PRICE_INFO['PROB_HIGH'] = DF_PRICE_INFO['DAY_UP'] / DF_PRICE_INFO['Freq']\n",
    "DF_PRICE_INFO['PROB_DWN'] = DF_PRICE_INFO['DAY_DWN'] / DF_PRICE_INFO['Freq']\n",
    "DF_PRICE_INFO['PROB_FLAT'] = DF_PRICE_INFO['DAY_FLAT'] / DF_PRICE_INFO['Freq']\n",
    "\n",
    "DF_PRICE_INFO['PROB_DAY_ABOVE_LCLSE'] = DF_PRICE_INFO['DAYS_ABOVE_LCLSE'] / DF_PRICE_INFO['Freq']\n",
    "DF_PRICE_INFO['PROB_DAY_BELOW_LCLSE'] = DF_PRICE_INFO['DAYS_BELOW_LCLSE'] / DF_PRICE_INFO['Freq']\n",
    "\n",
    "DF_PRICE_INFO['CHG_RTE_PRICE'] = DF_PRICE_INFO['Last_Close_price'] / DF_PRICE_INFO['First_Open_price'] -1\n",
    "\n",
    "del HIST_PRICE_DF_SUM, HIST_PRICE_DF_FIRST, HIST_PRICE_DF_LAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_YFIN_INFO1 = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_INFO_1.csv',sep='|') \n",
    "DF_YFIN_INFO2 = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_INFO_2.csv',sep='|') \n",
    "DF_YFIN_INFO3 = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_INFO_3.csv',sep='|') \n",
    "DF_YFIN_INFO4 = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_INFO_4.csv',sep='|') \n",
    "\n",
    "DF_YFIN_INFO = pd.concat([DF_YFIN_INFO1, DF_YFIN_INFO2, DF_YFIN_INFO3, DF_YFIN_INFO4], ignore_index=True)\n",
    "# DF_YFIN_INFO = pd.concat([DF_YFIN_INFO1, DF_YFIN_INFO2, DF_YFIN_INFO3], ignore_index=True)\n",
    "\n",
    "\n",
    "del DF_YFIN_INFO1, DF_YFIN_INFO2, DF_YFIN_INFO3, DF_YFIN_INFO4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep columns needed, selected after manual review\n",
    "\n",
    "DF_YFIN_INFO_SUBSET_VAR = DF_YFIN_INFO[[\n",
    "# Price / volume Movement\t\n",
    "'52WeekChange','fiftyDayAverage','fiftyTwoWeekHigh','fiftyTwoWeekLow','averageDailyVolume10Day','averageVolume10days',\n",
    "# Dividend\t\n",
    "'dividendRate','dividendYield','exDividendDate','payoutRatio','trailingAnnualDividendRate','trailingAnnualDividendYield',\n",
    "# Timing\t\n",
    "# 'mostRecentQuarter','lastFiscalYearEnd','lastSplitDate','nextFiscalYearEnd',\n",
    "# Fundamentals\t\n",
    "'open','marketCap','sharesOutstanding','floatShares','bookValue','regularMarketPrice','regularMarketVolume','heldPercentInsiders','heldPercentInstitutions',\n",
    "# Performance\t\n",
    "'earningsQuarterlyGrowth','netIncomeToCommon','beta','enterpriseToEbitda','enterpriseToRevenue','enterpriseValue','priceToBook','priceToSalesTrailing12Months','profitMargins','trailingEps','trailingPE','fullTimeEmployees',\n",
    "# Future dated\t\n",
    "'forwardEps','forwardPE',\n",
    "# Company Identifier\t\n",
    "'symbol'\n",
    "]]\n",
    "\n",
    "DF_YFIN_INFO_SUBSET_VAR.rename(columns={\"symbol\": \"TickName\"}, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "DF_YFIN_INFO_SUBSET_CHAR = DF_YFIN_INFO[[\t\n",
    "#Location\t\n",
    "'address1','address2','city','state','country','zip','exchange',\n",
    "# Company Identifier\t\n",
    "'symbol','shortName','longName',\n",
    "# ,'longBusinessSummary','website','messageBoardId',\n",
    "# Index Grouping\t\n",
    "'industry','sector'\n",
    "]]\n",
    "\n",
    "DF_YFIN_INFO_SUBSET_CHAR.rename(columns={\"symbol\": \"TickName\"}, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Create a sample for code testing purposes\n",
    "# DF_YFIN_INFO_SUBSET_VAR = DF_YFIN_INFO_SUBSET_VAR[DF_YFIN_INFO_SUBSET_VAR['TickName'].isin(['BHP.AX','RIO.AX','TCL.AX','CBA.AX','MQG.AX','CSL.AX','NAB.AX','WBC.AX','SCG.AX','ANZ.AX','FMG.AX','WES.AX','TLS.AX','RMD.AX','WOW.AX','APA.AX','ATM.AX','GMG.AX','STO.AX','AMC.AX','MGR.AX','COL.AX','ALL.AX','NCM.AX','ZIP.AX'])]\n",
    "# DF_YFIN_INFO_SUBSET_CHAR = DF_YFIN_INFO_SUBSET_CHAR[DF_YFIN_INFO_SUBSET_CHAR['TickName'].isin(['BHP.AX','RIO.AX','TCL.AX','CBA.AX','MQG.AX','CSL.AX','NAB.AX','WBC.AX','SCG.AX','ANZ.AX','FMG.AX','WES.AX','TLS.AX','RMD.AX','WOW.AX','APA.AX','ATM.AX','GMG.AX','STO.AX','AMC.AX','MGR.AX','COL.AX','ALL.AX','NCM.AX','ZIP.AX'])]\n",
    "\n",
    "\n",
    "# DF_YFIN_INFO_SUBSET = DF_YFIN_INFO_SUBSET[['TickName', 'sector']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add info onto prices data, add more features into this cell\n",
    "\n",
    "\n",
    "DF_YFIN_INFO_SUBSET_VAR.set_index('TickName')\n",
    "# DF_PRICE_INFO.set_index('TickName')\n",
    "\n",
    "\n",
    "ADDED_PRICE_INF = DF_PRICE_INFO.merge(DF_YFIN_INFO_SUBSET_VAR, on = 'TickName',how = 'left')\n",
    "# ADDED_PRICE_INF.to_excel('/Users/joezhou/Downloads/ADDED_PRICE_INF.xlsx', engine='xlsxwriter')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_DIV_HIST = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_Div.csv',sep='|') \n",
    "\n",
    "\n",
    "# DF_DIV_HIST_S = DF_DIV_HIST[DF_DIV_HIST['TickName'].isin(['CBA.AX','WES.AX'])]\n",
    "\n",
    "# find the last 5 year median dividend payout amount\n",
    "\n",
    "DF_DIV_HIST['DateTime'] = pd.to_datetime(DF_DIV_HIST['Date'], format='%Y-%m-%d')\n",
    "DF_DIV_HIST['Year'] = DF_DIV_HIST['DateTime'].dt.year\n",
    "\n",
    "DF_DIV_HIST_S = DF_DIV_HIST.groupby(['TickName', \"Year\"])['Dividends'].sum().reset_index()\n",
    "DF_DIV_HIST_S.sort_index(axis=1)\n",
    "\n",
    "DF_DIV_HIST_S2 = DF_DIV_HIST_S.groupby(\"TickName\").tail(5)\n",
    "# calculate the median as reference point\n",
    "DF_DIV_MED = DF_DIV_HIST_S2.groupby(['TickName'])['Dividends'].median().reset_index()\n",
    "\n",
    "\n",
    "\n",
    "del DF_DIV_HIST_S, DF_DIV_HIST_S2\n",
    "\n",
    "DF_DIV_MED.to_excel('/Users/joezhou/Downloads/DF_DIV_MED.xlsx', engine='xlsxwriter')  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# calulate flat valuation based on dividend returns\n",
    "# m = Number of payments per period (e.g., m=2 for semiannually payments)\n",
    "# t = Number of years to maturity\n",
    "# ytm = Yield to maturity (in decimals terms)\n",
    "# fv = The Bondâ€™s Face Value\n",
    "# c = Coupon rate (in decimals terms)\n",
    "    \n",
    "# bondPrice = ((fv*c/m*(1-(1+ytm/m)**(-m*t)))/(ytm/m)) + fv*(1+(ytm/m))**(-m*t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Ben Graham intrensic valuations and revse engineer a target growth rate based on latest closing price\n",
    "\n",
    "# the current yield on AAA corporate bonds (CURR_AAA_Y)\n",
    "CURR_AAA_Y = 3.38\n",
    "# the average yield of AAA corporate bonds (AVG_BND_Y)\n",
    "AVG_BND_Y = 4.4\n",
    "# EPS of non growing company (EPS_NG)\n",
    "EPS_NG = 8.5\n",
    "\n",
    "# reasonably expected 7 to 10 Year Growth Rate of EPS (EPS_G = 8.5)\n",
    "EPS_G = ADDED_PRICE_INF['earningsQuarterlyGrowth']*3\n",
    "\n",
    "# actual formula\n",
    "# ADDED_PRICE_INF['CALC_BF_IV'] = ADDED_PRICE_INF['trailingEps']*(EPS_NG+2*EPS_G))*AVG_BND_Y/CURR_AAA_Y\n",
    "# conservative\n",
    "ADDED_PRICE_INF['CALC_BF_IV'] = ADDED_PRICE_INF['trailingEps']*(EPS_NG+EPS_G)*AVG_BND_Y/CURR_AAA_Y\n",
    "\n",
    "ADDED_PRICE_INF['CALC_BF_GRWTH'] = (ADDED_PRICE_INF['Last_Close_price']*CURR_AAA_Y/AVG_BND_Y/ADDED_PRICE_INF['trailingEps']-EPS_NG)/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# FIN = pd.read_excel (r'/Users/joezhou/Downloads/ALL_FIN.xlsx') \n",
    "# FIN = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_FIN.csv',sep='|') \n",
    "FIN = pd.read_csv (r'/Users/joezhou/Downloads/ALL_FIN.csv',sep='|') \n",
    "\n",
    "\n",
    "#Create a sample for code testing purposes\n",
    "FIN_S = FIN[FIN['TickName'].isin(['WES.AX'])]\n",
    "FIN_S = FIN_S.loc[(FIN_S['Date'] == '2020-06-30')]\n",
    "\n",
    "#create a baselist for adding on the feature engineered variables\n",
    "# TICKER_LIST = FIN['TickName'].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caclulate WACC for Westfarmers\n",
    "\n",
    "FIN_S_T = FIN_S.pivot_table('Value', ['TickName', 'Date'], 'Metric')\n",
    "\n",
    "# FIN_S_T.to_excel('/Users/joezhou/Downloads/test_file.xlsx', engine='xlsxwriter')  \n",
    "\n",
    "FIN_S_T['C_TAX_R'] = FIN_S_T['Income Tax Expense']/ FIN_S_T['Income Before Tax']\n",
    "FIN_S_T['C_TOT_DEBT'] = FIN_S_T['Short Long Term Debt']+FIN_S_T['Long Term Debt']\n",
    "FIN_S_T['C_TOT_CPTL'] = FIN_S_T['C_TOT_DEBT'] + FIN_S_T['Total Stockholder Equity']\n",
    "\n",
    "FIN_S_T['C_TOT_DEBT_PERC'] = FIN_S_T['C_TOT_DEBT'] / FIN_S_T['C_TOT_CPTL']\n",
    "FIN_S_T['C_TOT_EQTY_PERC'] = 1 - FIN_S_T['C_TOT_DEBT_PERC']\n",
    "\n",
    "FIN_S_T['C_COST_DEBT'] = FIN_S_T['Long Term Debt'] / FIN_S_T['Total Assets']\n",
    "#need to work out cost of equity using westfarmers excel sheet\n",
    "FIN_S_T['C_COST_EQTY'] = 0.0502\n",
    "\n",
    "FIN_S_T['C_WACC'] = (FIN_S_T['C_TOT_DEBT_PERC']* FIN_S_T['C_COST_DEBT']) + (FIN_S_T['C_TOT_EQTY_PERC']*FIN_S_T['C_COST_EQTY'])*(1-FIN_S_T['C_TAX_R'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract variables and formatting\n",
    "FIN_S2 = FIN_S[FIN_S['Metric'].isin(['Short Long Term Debt','Total Stockholder Equity'])]\n",
    "# the above used to calculate debt and equity rate\n",
    "\n",
    "# risk free rate, use the 10 year bond rate\n",
    "RF = .01\n",
    "\n",
    "# BETA = use from the info section\n",
    "\n",
    "# Gross yield\n",
    "average_return = 5.63\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find correlating variables\n",
    "df = ADDED_PRICE_INF\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Create correlation matrix\n",
    "corr_matrix = df.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "upper.to_excel('/Users/joezhou/Downloads/corr_matrix.xlsx', engine='xlsxwriter')  \n",
    "\n",
    "# Find features with correlation greater than 0.7\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.7)]\n",
    "\n",
    "# Drop features \n",
    "df.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster to find similar performing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# from kneed import KneeLocator\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(init='random', n_clusters=3, random_state=42)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, true_labels = make_blobs(\n",
    "n_samples=200,\n",
    "centers=3,\n",
    "cluster_std=2.75,\n",
    "random_state=42\n",
    " )\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "kmeans = KMeans(\n",
    "   init=\"random\",\n",
    "   n_clusters=3,\n",
    "   n_init=10,\n",
    "   max_iter=300,\n",
    "   random_state=42\n",
    "   )\n",
    "\n",
    "\n",
    "kmeans.fit(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sector related models\n",
    "MOD_DATA = ADDED_PRICE_INF[['TickName','PROB_HIGH','CHG_RTE_PRICE','sector']]\n",
    "\n",
    "# padding rows into columns of 1 or 0\n",
    "# MOD_DATA = pd.concat([MOD_DATA, pd.get_dummies(MOD_DATA['sector'])], axis=1);\n",
    "\n",
    "\n",
    "# transpose for excel movement correlations\n",
    "\n",
    "\n",
    "MOD_DATA2 = MOD_DATA.pivot_table('PROB_HIGH', ['TickName','CHG_RTE_PRICE'], 'sector')\n",
    "\n",
    "#Export version for Tableau\n",
    "\n",
    "MOD_DATA2.to_excel('/Users/joezhou/Downloads/T_SECTOR_MODEL2.xls', index=False)\n",
    "\n",
    "\n",
    "# del MOD_DATA['sector'], MOD_DATA['TickName']\n",
    "\n",
    "# np.array(MOD_DATA, dtype=bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into dependent and independent vars\n",
    "# x_columns  = MOD_DATA.iloc[: , 4:]\n",
    "# y = MOD_DATA[\"PROB_HIGH\"]\n",
    "\n",
    "\n",
    "## creating function to get model statistics\n",
    "# import numpy as np\n",
    "# import statsmodels.api as sm\n",
    "# def get_stats():\n",
    "#     x = MOD_DATA[x_columns]\n",
    "#     results = sm.OLS(y, x).fit()\n",
    "#     print(results.summary())\n",
    "# get_stats()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29ef60e46f341bb51c2a63b17c19fb7c83213fa52e6b916fbf12c8b5ee03317f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

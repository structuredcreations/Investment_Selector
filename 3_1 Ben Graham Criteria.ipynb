{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import Info\n",
    "DF_YFIN_INFO1 = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_INFO_1.csv',sep='|') \n",
    "DF_YFIN_INFO2 = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_INFO_2.csv',sep='|') \n",
    "DF_YFIN_INFO3 = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_INFO_3.csv',sep='|') \n",
    "DF_YFIN_INFO4 = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_INFO_4.csv',sep='|') \n",
    "\n",
    "DF_YFIN_INFO = pd.concat([DF_YFIN_INFO1, DF_YFIN_INFO2, DF_YFIN_INFO3, DF_YFIN_INFO4], ignore_index=True)\n",
    "# DF_YFIN_INFO = pd.concat([DF_YFIN_INFO1, DF_YFIN_INFO2, DF_YFIN_INFO3], ignore_index=True)\n",
    "\n",
    "\n",
    "del DF_YFIN_INFO1, DF_YFIN_INFO2, DF_YFIN_INFO3, DF_YFIN_INFO4\n",
    "\n",
    "DF_YFIN_INFO_VARS = list(DF_YFIN_INFO.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep key variables\n",
    "\n",
    "\n",
    "INF_SUBSET = DF_YFIN_INFO[[\n",
    "'symbol','sharesOutstanding',\n",
    "'totalRevenue','revenueQuarterlyGrowth','revenueGrowth','grossMargins','grossProfits',\n",
    "'currentRatio','totalAssets',\n",
    "'dividendRate','dividendYield','fiveYearAvgDividendYield',\n",
    "'earningsGrowth','earningsQuarterlyGrowth',\n",
    "'marketCap',\n",
    "'trailingPE',\n",
    "'industry','sector',\n",
    "\n",
    "# add variations for v2\n",
    "\n",
    "# Price to book of under 1.2\n",
    "'priceToBook',\n",
    "\n",
    "# debt to asset less than 1.1\n",
    "'totalDebt','totalAssets'\n",
    "\n",
    "\n",
    "\n",
    "# Price / volume Movement\t\n",
    "# '52WeekChange','fiftyDayAverage','fiftyTwoWeekHigh','fiftyTwoWeekLow','averageDailyVolume10Day','averageVolume10days',\n",
    "# Dividend\t\n",
    "# 'dividendRate','dividendYield','exDividendDate','payoutRatio','trailingAnnualDividendRate','trailingAnnualDividendYield',\n",
    "# Timing\t\n",
    "# 'mostRecentQuarter','lastFiscalYearEnd','lastSplitDate','nextFiscalYearEnd',\n",
    "# Fundamentals\t\n",
    "# 'open','marketCap','sharesOutstanding','floatShares','bookValue','regularMarketPrice','regularMarketVolume','heldPercentInsiders','heldPercentInstitutions',\n",
    "# Performance\t\n",
    "# 'earningsQuarterlyGrowth','netIncomeToCommon','beta','enterpriseToEbitda','enterpriseToRevenue','enterpriseValue','priceToBook','priceToSalesTrailing12Months','profitMargins','trailingEps','trailingPE','fullTimeEmployees',\n",
    "# Future dated\t\n",
    "# 'forwardEps','forwardPE',\n",
    "\n",
    "]]\n",
    "\n",
    "INF_SUBSET.rename(columns={\"symbol\": \"TickName\"}, inplace = True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply criteria\n",
    "# start with defensive stocks\n",
    "\n",
    "BG_CONS = INF_SUBSET\n",
    "\n",
    "BG_CONS['FLAG_2_SALES'] = np.where(BG_CONS['totalRevenue'] > 1000000000 , 1, 0)\n",
    "BG_CONS['FLAG_3_CURR_RATIO'] = np.where(BG_CONS['currentRatio'] > 1.5 , 1, 0)\n",
    "BG_CONS['FLAG_4_DIV'] = np.where((BG_CONS['dividendYield'] ) > 0, 1, 0)\n",
    "BG_CONS['FLAG_4_DIV_GTH'] = 0\n",
    "# INF_SUBSET['FLAG_4_DIV_GTH'] = np.where((INF_SUBSET['fiveYearAvgDividendYield']) > 0, 1, 0)\n",
    "\n",
    "\n",
    "BG_CONS['FLAG_5_ERN'] = np.where(BG_CONS['grossProfits'] > 0 , 1, 0)\n",
    "BG_CONS['FLAG_6_ERN_GTH'] = np.where(BG_CONS['earningsGrowth'] > .02 , 1, 0)\n",
    "\n",
    "# 7. Market cap < (asset - liability) * 1.5\n",
    "\n",
    "BG_CONS['FLAG_7_MKT_CAP'] = np.where(BG_CONS['marketCap'] > .02 , 1, 0)\n",
    "\n",
    "BG_CONS['FLAG_8_PE'] = np.where(BG_CONS['trailingPE'] < 15 , 1, 0)\n",
    "\n",
    "BG_CONS['FLAG_BG_SCORE'] = BG_CONS['FLAG_2_SALES'] + BG_CONS['FLAG_3_CURR_RATIO'] + BG_CONS['FLAG_4_DIV']+ BG_CONS['FLAG_4_DIV_GTH']+ BG_CONS['FLAG_5_ERN']+ BG_CONS['FLAG_6_ERN_GTH']+ BG_CONS['FLAG_7_MKT_CAP']\n",
    "\n",
    "\n",
    "BG_CONS_SUM = BG_CONS.groupby(['FLAG_BG_SCORE'])['TickName'].count().reset_index()\n",
    "\n",
    "BG_CONS.to_excel('/Users/joezhou/Downloads/BG_CONSERVATIVE.xlsx', engine='xlsxwriter')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply criteria\n",
    "# start with defensive stocks\n",
    "\n",
    "BG_ENT = INF_SUBSET\n",
    "\n",
    "BG_ENT['FLAG_2_SALES'] = np.where(BG_ENT['revenueGrowth'] > 0 , 1, 0)\n",
    "BG_ENT['FLAG_3_CURR_RATIO'] = np.where(BG_ENT['currentRatio'] > 1 , 1, 0)\n",
    "BG_ENT['FLAG_4_DIV'] = 0\n",
    "INF_SUBSET['FLAG_4_DIV_GTH'] = np.where((INF_SUBSET['fiveYearAvgDividendYield']) > 0, 1, 0)\n",
    "\n",
    "\n",
    "BG_ENT['FLAG_5_ERN'] = np.where(BG_ENT['grossProfits'] > 0 , 1, 0)\n",
    "BG_ENT['FLAG_6_ERN_GTH'] = np.where(BG_ENT['earningsGrowth'] > .02 , 1, 0)\n",
    "\n",
    "# 7. Market cap < (asset - liability) * 1.5\n",
    "\n",
    "BG_ENT['FLAG_7_MKT_CAP'] = np.where(BG_ENT['marketCap'] > .02 , 1, 0)\n",
    "\n",
    "BG_ENT['FLAG_8_PE'] = np.where(BG_ENT['trailingPE'] < 25 , 1, 0)\n",
    "\n",
    "BG_ENT['FLAG_BG_SCORE'] = BG_ENT['FLAG_2_SALES'] + BG_ENT['FLAG_3_CURR_RATIO'] + BG_ENT['FLAG_4_DIV']+ BG_ENT['FLAG_4_DIV_GTH']+ BG_ENT['FLAG_5_ERN']+ BG_ENT['FLAG_6_ERN_GTH']+ BG_ENT['FLAG_7_MKT_CAP']\n",
    "\n",
    "\n",
    "BG_ENT_SUM = BG_ENT.groupby(['FLAG_BG_SCORE'])['TickName'].count().reset_index()\n",
    "\n",
    "BG_ENT.to_excel('/Users/joezhou/Downloads/BG_ENTERPRISING.xlsx', engine='xlsxwriter')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# HIST_PRICE_DF = pd.read_excel (r'/Users/joezhou/Downloads/ALL_Prices.xlsx')\n",
    "HIST_PRICE_DF_RAW = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_Prices.csv', sep='|')\n",
    "\n",
    "#Create a sample for code testing purposes\n",
    "# HIST_PRICE_DF = HIST_PRICE_DF_RAW[HIST_PRICE_DF_RAW['TickName'].isin(['BHP.AX','RIO.AX','TCL.AX','CBA.AX','MQG.AX','CSL.AX','NAB.AX','WBC.AX','SCG.AX','ANZ.AX','FMG.AX','WES.AX','TLS.AX','RMD.AX','WOW.AX','APA.AX','ATM.AX','GMG.AX','STO.AX','AMC.AX','MGR.AX','COL.AX','ALL.AX','NCM.AX','ZIP.AX'])]\n",
    "\n",
    "HIST_PRICE_DF = HIST_PRICE_DF_RAW\n",
    "\n",
    "#create a baselist for adding on the feature engineered variables\n",
    "TICKER_LIST = HIST_PRICE_DF['TickName'].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-a80d6e694314>:27: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  HIST_PRICE_DF_SUM = HIST_PRICE_DF.groupby(\"TickName\")[\"Freq\", \"DAY_UP\",\"DAY_DWN\", \"DAY_FLAT\", \"DAY_CHANGE_NUM\", \"DAY_CHANGE_RATE\", \"DAYS_ABOVE_LCLSE\", \"DAYS_BELOW_LCLSE\"].sum()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# find ends of the data window\n",
    "HIST_PRICE_DF_FIRST = HIST_PRICE_DF.groupby(\"TickName\").first()\n",
    "HIST_PRICE_DF_FIRST.rename(columns={\"Open\": \"First_Open_price\"}, inplace = True)\n",
    "\n",
    "\n",
    "HIST_PRICE_DF_LAST = HIST_PRICE_DF.groupby(\"TickName\").last()\n",
    "HIST_PRICE_DF_LAST.rename(columns={\"Close\": \"Last_Close_price\"}, inplace = True)\n",
    "HIST_PRICE_DF = HIST_PRICE_DF.merge(HIST_PRICE_DF_LAST[['Last_Close_price']], on = 'TickName',how = 'left')\n",
    "\n",
    "\n",
    "# create calculated columns\n",
    "HIST_PRICE_DF['Freq'] = 1\n",
    "\n",
    "HIST_PRICE_DF['DAY_UP'] = np.where(HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] > 0, 1, 0)\n",
    "HIST_PRICE_DF['DAY_DWN'] = np.where(HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] < 0, 1, 0)\n",
    "HIST_PRICE_DF['DAY_FLAT'] = np.where(HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] == 0, 1, 0)\n",
    "\n",
    "HIST_PRICE_DF['DAY_CHANGE_RATE'] = HIST_PRICE_DF['Close'] / HIST_PRICE_DF['Open'] - 1\n",
    "HIST_PRICE_DF['DAY_CHANGE_NUM'] = HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] \n",
    "\n",
    "HIST_PRICE_DF['DAYS_ABOVE_LCLSE'] = np.where(HIST_PRICE_DF['Last_Close_price'] - HIST_PRICE_DF['Close'] > 0, 1, 0)\n",
    "HIST_PRICE_DF['DAYS_BELOW_LCLSE'] = np.where(HIST_PRICE_DF['Last_Close_price'] - HIST_PRICE_DF['Close'] < 0, 1, 0)\n",
    "\n",
    "# aggregate to ticker level for calcs\n",
    "HIST_PRICE_DF_SUM = HIST_PRICE_DF.groupby(\"TickName\")[\"Freq\", \"DAY_UP\",\"DAY_DWN\", \"DAY_FLAT\", \"DAY_CHANGE_NUM\", \"DAY_CHANGE_RATE\", \"DAYS_ABOVE_LCLSE\", \"DAYS_BELOW_LCLSE\"].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ticker level file\n",
    "\n",
    "DF_PRICE_INFO = HIST_PRICE_DF_SUM[[\"Freq\", \"DAY_UP\",\"DAY_DWN\", \"DAY_FLAT\", \"DAYS_ABOVE_LCLSE\", \"DAYS_BELOW_LCLSE\"]].merge(HIST_PRICE_DF_FIRST[['First_Open_price']], on = 'TickName',how = 'left')\n",
    "DF_PRICE_INFO = DF_PRICE_INFO.merge(HIST_PRICE_DF_LAST[['Last_Close_price']], on = 'TickName',how = 'left')\n",
    "\n",
    "# calculate at ticker level\n",
    "DF_PRICE_INFO['PROB_HIGH'] = DF_PRICE_INFO['DAY_UP'] / DF_PRICE_INFO['Freq']\n",
    "DF_PRICE_INFO['PROB_DWN'] = DF_PRICE_INFO['DAY_DWN'] / DF_PRICE_INFO['Freq']\n",
    "DF_PRICE_INFO['PROB_FLAT'] = DF_PRICE_INFO['DAY_FLAT'] / DF_PRICE_INFO['Freq']\n",
    "\n",
    "DF_PRICE_INFO['PROB_DAY_ABOVE_LCLSE'] = DF_PRICE_INFO['DAYS_ABOVE_LCLSE'] / DF_PRICE_INFO['Freq']\n",
    "DF_PRICE_INFO['PROB_DAY_BELOW_LCLSE'] = DF_PRICE_INFO['DAYS_BELOW_LCLSE'] / DF_PRICE_INFO['Freq']\n",
    "\n",
    "DF_PRICE_INFO['CHG_RTE_PRICE'] = DF_PRICE_INFO['Last_Close_price'] / DF_PRICE_INFO['First_Open_price'] -1\n",
    "\n",
    "del HIST_PRICE_DF_SUM, HIST_PRICE_DF_FIRST, HIST_PRICE_DF_LAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_PRICE_INFO.to_excel('/Users/joezhou/Downloads/Pricing_Inf_latest.xlsx', engine='xlsxwriter')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29ef60e46f341bb51c2a63b17c19fb7c83213fa52e6b916fbf12c8b5ee03317f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# HIST_PRICE_DF = pd.read_excel (r'/Users/joezhou/Downloads/ALL_Prices.xlsx')\n",
    "HIST_PRICE_DF_RAW = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_Prices.csv', sep='|')\n",
    "\n",
    "#Create a sample for code testing purposes\n",
    "# HIST_PRICE_DF = HIST_PRICE_DF_RAW[HIST_PRICE_DF_RAW['TickName'].isin(['BHP.AX','RIO.AX','TCL.AX','CBA.AX','MQG.AX','CSL.AX','NAB.AX','WBC.AX','SCG.AX','ANZ.AX','FMG.AX','WES.AX','TLS.AX','RMD.AX','WOW.AX','APA.AX','ATM.AX','GMG.AX','STO.AX','AMC.AX','MGR.AX','COL.AX','ALL.AX','NCM.AX','ZIP.AX'])]\n",
    "\n",
    "HIST_PRICE_DF = HIST_PRICE_DF_RAW\n",
    "\n",
    "#create a baselist for adding on the feature engineered variables\n",
    "TICKER_LIST = HIST_PRICE_DF['TickName'].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-b4abf3bd20ec>:18: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  HIST_PRICE_DF_SUM = HIST_PRICE_DF.groupby(\"TickName\")[\"Freq\", \"DAY_UP\",\"DAY_DWN\", \"DAY_FLAT\", \"DAY_CHANGE_NUM\", \"DAY_CHANGE_RATE\"].sum()\n"
     ]
    }
   ],
   "source": [
    "# Create tag variables\n",
    "# Calculated higher or lower\n",
    "# daily change \n",
    "# daily change absolute\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "HIST_PRICE_DF['Freq'] = 1\n",
    "\n",
    "\n",
    "HIST_PRICE_DF['DAY_UP'] = np.where(HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] > 0, 1, 0)\n",
    "HIST_PRICE_DF['DAY_DWN'] = np.where(HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] < 0, 1, 0)\n",
    "HIST_PRICE_DF['DAY_FLAT'] = np.where(HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] == 0, 1, 0)\n",
    "\n",
    "HIST_PRICE_DF['DAY_CHANGE_RATE'] = HIST_PRICE_DF['Close'] / HIST_PRICE_DF['Open'] - 1\n",
    "HIST_PRICE_DF['DAY_CHANGE_NUM'] = HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] \n",
    "\n",
    "HIST_PRICE_DF_SUM = HIST_PRICE_DF.groupby(\"TickName\")[\"Freq\", \"DAY_UP\",\"DAY_DWN\", \"DAY_FLAT\", \"DAY_CHANGE_NUM\", \"DAY_CHANGE_RATE\"].sum()\n",
    "\n",
    "# calculate the magnitude of movement\n",
    "\n",
    "\n",
    "\n",
    "# HIST_PRICE_DF['Mvmt_val'] = HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open']\n",
    "# HIST_PRICE_DF['Mvmt_rate'] = HIST_PRICE_DF['Close'] / HIST_PRICE_DF['Open']-1\n",
    "\n",
    "# tag events\n",
    "\n",
    "# HIST_PRICE_DF.loc[HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] > 0, 'DAY_UP_VAL'] = HIST_PRICE_DF['Mvmt_val']\n",
    "# HIST_PRICE_DF.loc[HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] > 0, 'DAY_UP_RATE'] = HIST_PRICE_DF['Mvmt_rate']\n",
    "\n",
    "# down movements\n",
    "# HIST_PRICE_DF.loc[HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] < 0, 'DAY_DWN_VAL'] = HIST_PRICE_DF['Mvmt_val']\n",
    "# HIST_PRICE_DF.loc[HIST_PRICE_DF['Close'] - HIST_PRICE_DF['Open'] < 0, 'DAY_DWN_RATE'] = HIST_PRICE_DF['Mvmt_rate']\n",
    "\n",
    "# Aggregate to ticker level\n",
    "\n",
    "# HIST_PRICE_DF_SUM = HIST_PRICE_DF.groupby(\"TickName\")[\"DAY_UP\", \"Freq\", \"DAY_UP_VAL\", \"DAY_UP_RATE\" , \"DAY_DWN_VAL\",\"DAY_DWN_RATE\" ].sum()\n",
    "# HIST_PRICE_DF_MED = HIST_PRICE_DF.groupby(\"TickName\")[\"DAY_UP_VAL\", \"DAY_UP_RATE\", \"DAY_DWN_VAL\",\"DAY_DWN_RATE\" ].median()\n",
    "# HIST_PRICE_DF_AVG = HIST_PRICE_DF.groupby(\"TickName\")[\"DAY_UP_VAL\", \"DAY_UP_RATE\", \"DAY_DWN_VAL\",\"DAY_DWN_RATE\" ].mean()\n",
    "\n",
    "\n",
    "# def f(grp):\n",
    "#     return pd.DataFrame({\n",
    "#                 'N_DAYS':len(grp),\n",
    "#                 'N_UP_DAYS': grp['DAY_UP'].sum(),\n",
    "#                 'Percentage of Up days': grp['DAY_UP'].mean(),\n",
    "#                 'Average daily change':grp['DAY_CHANGE_RATE'].mean(),\n",
    "#                 'Median daily change':grp['DAY_CHANGE_RATE'].median(),\n",
    "#                 }\n",
    "                # ,\n",
    "\n",
    "                # 'NEW_VAR': grp['C'].mean() / grp['X'].sum()},  # <--- here we access different columns...\n",
    "                # index=[grp.name]\n",
    "                # )\n",
    "# ## -- End pasted text --\n",
    "\n",
    "# HIST_PRICE_DF_SUM = HIST_PRICE_DF.groupby('TickName', as_index=False).apply(f)\n",
    "\n",
    "\n",
    "HIST_PRICE_DF_FIRST = HIST_PRICE_DF.groupby(\"TickName\").first()\n",
    "HIST_PRICE_DF_LAST = HIST_PRICE_DF.groupby(\"TickName\").last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ticker level file\n",
    "\n",
    "DF_PRICE_INFO = HIST_PRICE_DF_SUM[[\"Freq\", \"DAY_UP\",\"DAY_DWN\", \"DAY_FLAT\"]].merge(HIST_PRICE_DF_FIRST[['Open']], on = 'TickName',how = 'left')\n",
    "DF_PRICE_INFO = DF_PRICE_INFO.merge(HIST_PRICE_DF_LAST[['Close']], on = 'TickName',how = 'left')\n",
    "\n",
    "# calculate at ticker level\n",
    "DF_PRICE_INFO['PROB_HIGH'] = DF_PRICE_INFO['DAY_UP'] / DF_PRICE_INFO['Freq']\n",
    "DF_PRICE_INFO['PROB_DWN'] = DF_PRICE_INFO['DAY_DWN'] / DF_PRICE_INFO['Freq']\n",
    "DF_PRICE_INFO['PROB_FLAT'] = DF_PRICE_INFO['DAY_FLAT'] / DF_PRICE_INFO['Freq']\n",
    "\n",
    "DF_PRICE_INFO['CHG_RTE_PRICE'] = DF_PRICE_INFO['Close'] / DF_PRICE_INFO['Open'] -1\n",
    "\n",
    "del HIST_PRICE_DF_SUM, HIST_PRICE_DF_FIRST, HIST_PRICE_DF_LAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_YFIN_INFO1 = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_INFO_1.csv',sep='|') \n",
    "DF_YFIN_INFO2 = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_INFO_2.csv',sep='|') \n",
    "DF_YFIN_INFO3 = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_INFO_3.csv',sep='|') \n",
    "DF_YFIN_INFO4 = pd.read_csv (r'/Users/joezhou/Downloads/R_ALL_INFO_4.csv',sep='|') \n",
    "\n",
    "DF_YFIN_INFO = pd.concat([DF_YFIN_INFO1, DF_YFIN_INFO2, DF_YFIN_INFO3, DF_YFIN_INFO4], ignore_index=True)\n",
    "# DF_YFIN_INFO = pd.concat([DF_YFIN_INFO1, DF_YFIN_INFO2, DF_YFIN_INFO3], ignore_index=True)\n",
    "\n",
    "\n",
    "del DF_YFIN_INFO1, DF_YFIN_INFO2, DF_YFIN_INFO3, DF_YFIN_INFO4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep columns needed, selected after manual review\n",
    "\n",
    "DF_YFIN_INFO_SUBSET = DF_YFIN_INFO[[\n",
    "# Price / volume Movement\t\n",
    "'52WeekChange','fiftyDayAverage','fiftyTwoWeekHigh','fiftyTwoWeekLow','averageDailyVolume10Day','averageVolume10days',\n",
    "#Location\t\n",
    "'address1','address2','city','state','country','zip','exchange',\n",
    "# Dividend\t\n",
    "'dividendRate','dividendYield','exDividendDate','payoutRatio','trailingAnnualDividendRate','trailingAnnualDividendYield',\n",
    "# Timing\t\n",
    "'mostRecentQuarter','lastFiscalYearEnd','lastSplitDate','nextFiscalYearEnd',\n",
    "# Fundamentals\t\n",
    "'open','marketCap','sharesOutstanding','floatShares','bookValue','regularMarketPrice','regularMarketVolume','heldPercentInsiders','heldPercentInstitutions',\n",
    "# Performance\t\n",
    "'earningsQuarterlyGrowth','netIncomeToCommon','beta','enterpriseToEbitda','enterpriseToRevenue','enterpriseValue','priceToBook','priceToSalesTrailing12Months','profitMargins','trailingEps','trailingPE','fullTimeEmployees',\n",
    "# Future dated\t\n",
    "'forwardEps','forwardPE',\n",
    "# Company Identifier\t\n",
    "'symbol','shortName','longName',\n",
    "# ,'longBusinessSummary','website','messageBoardId',\n",
    "# Index Grouping\t\n",
    "'industry','sector'\n",
    "]]\n",
    "\n",
    "DF_YFIN_INFO_SUBSET.rename(columns={\"symbol\": \"TickName\"}, inplace = True)\n",
    "\n",
    "\n",
    "#Create a sample for code testing purposes\n",
    "# DF_YFIN_INFO_SUBSET = DF_YFIN_INFO_SUBSET[DF_YFIN_INFO_SUBSET['TickName'].isin(['BHP.AX','RIO.AX','TCL.AX','CBA.AX','MQG.AX','CSL.AX','NAB.AX','WBC.AX','SCG.AX','ANZ.AX','FMG.AX','WES.AX','TLS.AX','RMD.AX','WOW.AX','APA.AX','ATM.AX','GMG.AX','STO.AX','AMC.AX','MGR.AX','COL.AX','ALL.AX','NCM.AX','ZIP.AX'])]\n",
    "\n",
    "\n",
    "# DF_YFIN_INFO_SUBSET = DF_YFIN_INFO_SUBSET[['TickName', 'sector']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add info onto prices data\n",
    "\n",
    "\n",
    "DF_YFIN_INFO_SUBSET.set_index('TickName')\n",
    "# DF_PRICE_INFO.set_index('TickName')\n",
    "\n",
    "\n",
    "ADDED_PRICE_INF = DF_PRICE_INFO.merge(DF_YFIN_INFO_SUBSET, on = 'TickName',how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sector related models\n",
    "MOD_DATA = ADDED_PRICE_INF[['TickName','PROB_HIGH','CHG_RTE_PRICE','sector']]\n",
    "\n",
    "# padding rows into columns of 1 or 0\n",
    "MOD_DATA = pd.concat([MOD_DATA, pd.get_dummies(MOD_DATA['sector'])], axis=1);\n",
    "\n",
    "#Export version for Tableau\n",
    "\n",
    "MOD_DATA.to_excel('/Users/joezhou/Downloads/T_SECTOR_MODEL.xls', index=False)\n",
    "\n",
    "\n",
    "# del MOD_DATA['sector'], MOD_DATA['TickName']\n",
    "\n",
    "# np.array(MOD_DATA, dtype=bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Boolean array expected for the condition, not uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-1a8da8006505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mget_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-1a8da8006505>\u001b[0m in \u001b[0;36mget_stats\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMOD_DATA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2887\u001b[0m         \u001b[0;31m# Do we have a (boolean) DataFrame?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2888\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2889\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2891\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(self, cond, other, inplace, axis, level, errors, try_cast)\u001b[0m\n\u001b[1;32m   9002\u001b[0m         \"\"\"\n\u001b[1;32m   9003\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9004\u001b[0;31m         return self._where(\n\u001b[0m\u001b[1;32m   9005\u001b[0m             \u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_cast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtry_cast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9006\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_where\u001b[0;34m(self, cond, other, inplace, axis, level, errors, try_cast)\u001b[0m\n\u001b[1;32m   8764\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8765\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_bool_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8766\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8767\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8768\u001b[0m             \u001b[0;31m# GH#21947 we have an empty DataFrame/Series, could be object-dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Boolean array expected for the condition, not uint8"
     ]
    }
   ],
   "source": [
    "# split into dependent and independent vars\n",
    "x_columns  = MOD_DATA.iloc[: , 4:]\n",
    "y = MOD_DATA[\"PROB_HIGH\"]\n",
    "\n",
    "\n",
    "## creating function to get model statistics\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "def get_stats():\n",
    "    x = MOD_DATA[x_columns]\n",
    "    results = sm.OLS(y, x).fit()\n",
    "    print(results.summary())\n",
    "get_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29ef60e46f341bb51c2a63b17c19fb7c83213fa52e6b916fbf12c8b5ee03317f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

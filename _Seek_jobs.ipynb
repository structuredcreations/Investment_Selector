{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source website\n",
    "# https://github.com/PyBites-Open-Source/job-seeker\n",
    "\n",
    "# Setup: install backages via terminal\n",
    "\n",
    "# pip install job-seeker\n",
    "\n",
    "# git clone https://github.com/pedrojunqueira/job-seeker.git\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from job_seeker.downloader import JobSeeker\n",
    "# Note: the output is capped at 550 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Underling Code from github\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "class JobSeeker:\n",
    "\n",
    "    SEEK_API_URL = \"https://www.seek.com.au/api/chalice-search/search\"\n",
    "    SEEK_API_URL_JOB = \"https://chalice-experience-api.cloud.seek.com.au/job\"\n",
    "\n",
    "    def __init__(self, params: dict) -> None:\n",
    "\n",
    "        self.default_params = dict(\n",
    "            siteKey=\"AU-Main\",\n",
    "            sourcesystem=\"houston\",\n",
    "            page=\"1\",\n",
    "            seekSelectAllPages=\"true\",\n",
    "        )\n",
    "        self.params = dict(self.default_params, **params)\n",
    "        self.total_count = self._get_jobs_count()\n",
    "        self.jobs_df = self._current_jobs_to_df()\n",
    "        self.df_io = self._df_to_io_output(self.jobs_df)\n",
    "        self.jobs_id = self._extract_list_job_ids()\n",
    "        self.jobs_detail_json = None\n",
    "\n",
    "    def _get_jobs_count(self) -> int:\n",
    "        r = requests.get(url=self.SEEK_API_URL, params=self.params)\n",
    "        json_response = r.json()\n",
    "        return json_response.get(\"totalCount\")\n",
    "\n",
    "    def _total_pages(self, jobs_count) -> int:\n",
    "        return int(round(jobs_count / 20, 0))\n",
    "\n",
    "    def _current_jobs_to_df(self) -> pd.DataFrame:\n",
    "\n",
    "        jobs_data = defaultdict(list)\n",
    "\n",
    "        for page in range(1, self._total_pages(self.total_count) + 1):\n",
    "\n",
    "            q_params = self.params\n",
    "            q_params[\"page\"] = str(page)\n",
    "\n",
    "            r = requests.get(self.SEEK_API_URL, params=q_params)\n",
    "            if r.ok:\n",
    "\n",
    "                data = r.json()\n",
    "\n",
    "                for job in data.get(\"data\"):\n",
    "                    job_id = job.get(\"id\")\n",
    "                    listing_date = job.get(\"listingDate\")\n",
    "                    title = job.get(\"title\")\n",
    "                    teaser = job.get(\"teaser\")\n",
    "                    company_advertiser = job.get(\"advertiser\")[\"description\"]\n",
    "                    classification = job.get(\"classification\")[\"description\"]\n",
    "                    location = job.get(\"location\")\n",
    "                    salary = job.get(\"salary\")\n",
    "                    companyName = job.get(\"companyName\")\n",
    "                    role_id = job.get(\"roleId\")\n",
    "                    isPrivateAdvertiser = job.get(\"isPrivateAdvertiser\")\n",
    "                    suburbWhereValue = job.get(\"suburbWhereValue\")\n",
    "                    subClassification = job.get(\"subClassification\")[\"description\"]\n",
    "                    workType = job.get(\"workType\")\n",
    "\n",
    "                    jobs_data[\"page\"].append(page)\n",
    "                    jobs_data[\"job_id\"].append(job_id)\n",
    "                    jobs_data[\"title\"].append(title)\n",
    "                    jobs_data[\"role_id\"].append(role_id)\n",
    "                    jobs_data[\"listing_date\"].append(listing_date)\n",
    "                    jobs_data[\"teaser\"].append(teaser)\n",
    "                    jobs_data[\"classification\"].append(classification)\n",
    "                    jobs_data[\"subClassification\"].append(subClassification)\n",
    "                    jobs_data[\"workType\"].append(workType)\n",
    "                    jobs_data[\"location\"].append(location)\n",
    "                    jobs_data[\"suburbWhereValue\"].append(suburbWhereValue)\n",
    "                    jobs_data[\"salary\"].append(salary)\n",
    "                    jobs_data[\"companyName\"].append(companyName)\n",
    "                    jobs_data[\"company_advertiser\"].append(company_advertiser)\n",
    "                    jobs_data[\"isPrivateAdvertiser\"].append(isPrivateAdvertiser)\n",
    "\n",
    "        jobs_df = pd.DataFrame(jobs_data)\n",
    "\n",
    "        return jobs_df\n",
    "\n",
    "    def _df_to_io_output(self, df):\n",
    "        return df.to_csv(index=False)\n",
    "\n",
    "    def _extract_list_job_ids(self) -> list:\n",
    "        if \"job_id\" in self.jobs_df.columns:\n",
    "            return self.jobs_df[\"job_id\"].to_list()\n",
    "\n",
    "    def get_jobs_detail_json(self):\n",
    "        jobs_detail = list()\n",
    "        for job in self.jobs_id:\n",
    "            r = requests.get(f\"{self.SEEK_API_URL_JOB}/{job}\")\n",
    "            if r.ok:\n",
    "                print(f\"downloading... job {job}\")\n",
    "                job_data = r.json()\n",
    "                jobs_detail.append(job_data)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from job_seeker.downloader import JobSeeker\n",
    "\n",
    "# set parameters\n",
    "\n",
    "parameters = {\n",
    "    \"keywords\" : \"analytics\",\n",
    "    \"subClassification\" : \"Management\",\n",
    "    \"location\" : \"Sydney\",\n",
    "    \"workType\" : \"Full Time\",\n",
    "}\n",
    "\n",
    "#instantiate the JobSeeker class\n",
    "\n",
    "js = JobSeeker(params=parameters)\n",
    "\n",
    "df = js.jobs_df\n",
    "\n",
    "# df is a pandas.DataFrame object\n",
    "\n",
    "# to print DataFrame head\n",
    "# print(df.head())\n",
    "\n",
    "\n",
    "# to save as a csv in the current directory. See example on the ./example folder\n",
    "# df.to_csv(\"my_job_search.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('/Users/joezhou/Downloads/SEEK_EXTRACT.xls', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29ef60e46f341bb51c2a63b17c19fb7c83213fa52e6b916fbf12c8b5ee03317f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and dataset\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# Adjust pandas display options\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent truncation\n",
    "\n",
    "\n",
    "df = pd.read_csv('/Users/joezhou/Downloads/Mentum Assignment Data/Customer-churn-records.csv',sep=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing from assignment 1\n",
    "\n",
    "\n",
    "# Convert categorical variables into numerical variables to understand relationship to churn for correlation analysis\n",
    "\n",
    "# Drop columns that are not needed (e.g., RowNumber, CustomerId, Surname)\n",
    "df2 = df\n",
    "df2.drop(columns=['RowNumber', 'CustomerId', 'Surname'], inplace=True)\n",
    "# Note: drop complain variable due to perfect correlation with churn, skewing the model\n",
    "df2.drop(columns='Complain')\n",
    "\n",
    "df_encoded = pd.get_dummies(df2, columns=['Geography', 'Gender', 'HasCrCard', 'IsActiveMember', 'Card Type'], drop_first=False)\n",
    "# Identify and convert boolean columns to integers\n",
    "bool_columns = df_encoded.select_dtypes(include='bool').columns\n",
    "df_encoded[bool_columns] = df_encoded[bool_columns].astype(int)\n",
    "# Note: drop some encoded variables that are binary in nature to remove data noise\n",
    "df_encoded.drop(columns=['HasCrCard_0','IsActiveMember_0'], inplace=True)\n",
    "\n",
    "# create new feature to capture $0 balances, based on assignment 1 findings\n",
    "df_encoded['Flag_Null_Balance'] = df_encoded['Balance'].apply(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Satisfaction Score</th>\n",
       "      <th>Point Earned</th>\n",
       "      <th>Geography_NSW</th>\n",
       "      <th>Geography_QLD</th>\n",
       "      <th>Geography_VIC</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>HasCrCard_1</th>\n",
       "      <th>IsActiveMember_1</th>\n",
       "      <th>Card Type_DIAMOND</th>\n",
       "      <th>Card Type_GOLD</th>\n",
       "      <th>Card Type_PLATINUM</th>\n",
       "      <th>Card Type_SILVER</th>\n",
       "      <th>Flag_Null_Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>456</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>350</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>425</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  EstimatedSalary  Exited  Complain  Satisfaction Score  Point Earned  Geography_NSW  Geography_QLD  Geography_VIC  Gender_Female  Gender_Male  HasCrCard_1  IsActiveMember_1  Card Type_DIAMOND  Card Type_GOLD  Card Type_PLATINUM  Card Type_SILVER  Flag_Null_Balance\n",
       "0          619   42       2       0.00              1        101348.88       1         1                   2           464              1              0              0              1            0            1                 1                  1               0                   0                 0                  1\n",
       "1          608   41       1   83807.86              1        112542.58       0         1                   3           456              0              1              0              1            0            0                 1                  1               0                   0                 0                  0\n",
       "2          502   42       8  159660.80              3        113931.57       1         1                   3           377              1              0              0              1            0            1                 0                  1               0                   0                 0                  0\n",
       "3          699   39       1       0.00              2         93826.63       0         0                   5           350              1              0              0              1            0            0                 0                  0               1                   0                 0                  1\n",
       "4          850   43       2  125510.82              1         79084.10       0         0                   5           425              0              1              0              1            0            1                 1                  0               1                   0                 0                  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modelling libraries\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Split data into training and test for model development\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = df_encoded.drop('Exited', axis=1)  # Features\n",
    "y = df_encoded['Exited']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9986666666666667\n",
      "Confusion Matrix:\n",
      "[[2413    3]\n",
      " [   1  583]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2416\n",
      "           1       0.99      1.00      1.00       584\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       1.00      1.00      1.00      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n",
      "               Feature  Coefficient  Absolute Coefficient\n",
      "6             Complain     5.042340              5.042340\n",
      "1                  Age     0.744098              0.744098\n",
      "15    IsActiveMember_1    -0.455451              0.455451\n",
      "8         Point Earned    -0.396681              0.396681\n",
      "3              Balance     0.358884              0.358884\n",
      "20   Flag_Null_Balance     0.253204              0.253204\n",
      "18  Card Type_PLATINUM    -0.233145              0.233145\n",
      "7   Satisfaction Score    -0.231767              0.231767\n",
      "5      EstimatedSalary    -0.155731              0.155731\n",
      "19    Card Type_SILVER     0.132977              0.132977\n",
      "13         Gender_Male    -0.128152              0.128152\n",
      "12       Gender_Female     0.128152              0.128152\n",
      "0          CreditScore     0.118338              0.118338\n",
      "10       Geography_QLD     0.102257              0.102257\n",
      "11       Geography_VIC    -0.097630              0.097630\n",
      "14         HasCrCard_1    -0.084730              0.084730\n",
      "2               Tenure    -0.079338              0.079338\n",
      "17      Card Type_GOLD     0.074691              0.074691\n",
      "4        NumOfProducts    -0.061663              0.061663\n",
      "16   Card Type_DIAMOND     0.027423              0.027423\n",
      "9        Geography_NSW    -0.004170              0.004170\n"
     ]
    }
   ],
   "source": [
    "# Part 1.1: Logistic regression model\n",
    "\n",
    "# Standardize the feature variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# supporting material for p\n",
    "# Feature importance (coefficients)\n",
    "# coefficients = pd.DataFrame(model.coef_.flatten(), index=X.columns, columns=['Coefficient'])\n",
    "# coefficients = coefficients.sort_values(by='Coefficient', ascending=False)\n",
    "# print(coefficients)\n",
    "\n",
    "# Extracting coefficients\n",
    "coefficients = pd.DataFrame({'Feature': X.columns, 'Coefficient': log_reg.coef_[0]})\n",
    "coefficients['Absolute Coefficient'] = coefficients['Coefficient'].abs()\n",
    "coefficients = coefficients.sort_values(by='Absolute Coefficient', ascending=False)\n",
    "\n",
    "print(coefficients)\n",
    "\n",
    "\n",
    "# Visualize feature importance\n",
    "# plt.figure(figsize=(10,6))\n",
    "# sns.barplot(x=coefficients['Coefficient'], y=coefficients.index)\n",
    "# plt.title('Feature Importance (Logistic Regression Coefficients)')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = df_encoded.DataFrame(model.coef_.flatten(), index=X.columns, columns=['Coefficient'])\n",
    "coefficients = coefficients.sort_values(by='Coefficient', ascending=False)\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1.2: Random Forrest Model\n",
    "\n",
    "\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = df_encoded.drop('Exited', axis=1)  # Features\n",
    "y = df_encoded['Exited']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Random Forest model\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1.3: Gradient boost machines\n",
    "\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = df_encoded.drop('Exited', axis=1)  # Features\n",
    "y = df_encoded['Exited']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gb_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1.4: Decision Tree\n",
    "\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = df_encoded.drop('Exited', axis=1)  # Features\n",
    "y = df_encoded['Exited']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = dt_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Feature Importance - Sorting by most important\n",
    "feature_importance = dt_classifier.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "# Create a sorted list of features by importance\n",
    "sorted_indices = np.argsort(feature_importance)[::-1]\n",
    "sorted_features = features[sorted_indices]\n",
    "sorted_importance = feature_importance[sorted_indices]\n",
    "\n",
    "# Print sorted feature importance\n",
    "print(\"Sorted Feature Importance:\")\n",
    "for feature, importance in zip(sorted_features, sorted_importance):\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "# Plot sorted feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(sorted_features, sorted_importance, color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance from Decision Tree')\n",
    "plt.gca().invert_yaxis()  # To have the most important feature at the top\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dt_classifier, feature_names=features, class_names=['Not Exited', 'Exited'], filled=True, rounded=True)\n",
    "plt.title(\"Decision Tree Visualization\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Print the decision tree structure as text\n",
    "# tree_rules = export_text(dt_classifier, feature_names=list(features))\n",
    "# print(\"Decision Tree Structure:\")\n",
    "# print(tree_rules)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: the 1st decision tree is large, selecting the top 10 variables for the next iteration\n",
    "\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = df_encoded.drop('Exited', axis=1)  # Features\n",
    "y = df_encoded['Exited']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initial Decision Tree Classifier to get feature importance\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Feature Importance - Sorting by most important\n",
    "feature_importance = dt_classifier.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "# Set a threshold for feature importance (e.g., 0.01)\n",
    "importance_threshold = 0.05\n",
    "\n",
    "# Shortlist important features based on the threshold\n",
    "sorted_indices = np.argsort(feature_importance)[::-1]\n",
    "sorted_features = features[sorted_indices]\n",
    "sorted_importance = feature_importance[sorted_indices]\n",
    "\n",
    "important_features = sorted_features[sorted_importance >= importance_threshold]\n",
    "important_importance = sorted_importance[sorted_importance >= importance_threshold]\n",
    "\n",
    "# Print shortlisted important features\n",
    "print(f\"Shortlisted Important Features (Threshold: {importance_threshold}):\")\n",
    "for feature, importance in zip(important_features, important_importance):\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "# Plot shortlisted feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(important_features, important_importance, color='lightgreen')\n",
    "plt.xlabel('Importance')\n",
    "plt.title(f'Shortlisted Feature Importance (Threshold: {importance_threshold})')\n",
    "plt.gca().invert_yaxis()  # To have the most important feature at the top\n",
    "plt.show()\n",
    "\n",
    "# Train a new Decision Tree using only the shortlisted important features\n",
    "X_train_important = X_train[important_features]\n",
    "X_test_important = X_test[important_features]\n",
    "\n",
    "# Decision Tree with shortlisted important features\n",
    "dt_classifier_important = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier_important.fit(X_train_important, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_important = dt_classifier_important.predict(X_test_important)\n",
    "\n",
    "# Evaluate the model with shortlisted features\n",
    "accuracy_important = accuracy_score(y_test, y_pred_important)\n",
    "conf_matrix_important = confusion_matrix(y_test, y_pred_important)\n",
    "class_report_important = classification_report(y_test, y_pred_important)\n",
    "\n",
    "# Print the results for the model with shortlisted features\n",
    "print(f\"Accuracy with shortlisted features: {accuracy_important}\")\n",
    "print(\"Confusion Matrix with shortlisted features:\")\n",
    "print(conf_matrix_important)\n",
    "print(\"Classification Report with shortlisted features:\")\n",
    "print(class_report_important)\n",
    "\n",
    "# Plot the decision tree with the shortlisted important features\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dt_classifier_important, feature_names=important_features, class_names=['Not Exited', 'Exited'], filled=True, rounded=True)\n",
    "plt.title(\"Decision Tree Visualization with Shortlisted Features\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply hyper tuninng\n",
    "\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = df_encoded.drop('Exited', axis=1)  # Features\n",
    "y = df_encoded['Exited']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initial Decision Tree Classifier to get feature importance\n",
    "dt_classifier = DecisionTreeClassifier(    random_state=42,\n",
    "                                            max_depth=2,               # Limit the depth of the tree\n",
    "                                            min_samples_split=10,      # Minimum samples required to split a node\n",
    "                                            min_samples_leaf=5,        # Minimum samples required at a leaf node\n",
    "                                            max_leaf_nodes=5          # Limit the number of leaf nodes\n",
    "                                        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dt_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Feature Importance - Sorting by most important\n",
    "feature_importance = dt_classifier.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "# Set a threshold for feature importance\n",
    "importance_threshold = 0.11\n",
    "\n",
    "# Shortlist important features based on the threshold\n",
    "sorted_indices = np.argsort(feature_importance)[::-1]\n",
    "sorted_features = features[sorted_indices]\n",
    "sorted_importance = feature_importance[sorted_indices]\n",
    "\n",
    "important_features = sorted_features[sorted_importance >= importance_threshold]\n",
    "important_importance = sorted_importance[sorted_importance >= importance_threshold]\n",
    "\n",
    "# Manually dropping some variables from the shortlisted features\n",
    "manual_drops = ['EstimatedSalary', 'Complain']  # Add or remove variables to drop\n",
    "important_features_filtered = [feat for feat in important_features if feat not in manual_drops]\n",
    "\n",
    "# Print shortlisted important features after manual dropping\n",
    "print(f\"Shortlisted Important Features (after manual dropping, Threshold: {importance_threshold}):\")\n",
    "for feature in important_features_filtered:\n",
    "    print(feature)\n",
    "\n",
    "# Train a new Decision Tree using only the filtered important features\n",
    "X_train_filtered = X_train[important_features_filtered]\n",
    "X_test_filtered = X_test[important_features_filtered]\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,\n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data with hyperparameter tuning\n",
    "grid_search.fit(X_train_filtered, y_train)\n",
    "\n",
    "# Get the best parameters from GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters from GridSearchCV: {best_params}\")\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "best_dt_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred_filtered = best_dt_classifier.predict(X_test_filtered)\n",
    "\n",
    "# Evaluate the model with the optimized hyperparameters\n",
    "accuracy_filtered = accuracy_score(y_test, y_pred_filtered)\n",
    "conf_matrix_filtered = confusion_matrix(y_test, y_pred_filtered)\n",
    "class_report_filtered = classification_report(y_test, y_pred_filtered)\n",
    "\n",
    "# Print the results for the model with optimized hyperparameters\n",
    "print(f\"Accuracy with filtered important features and optimized hyperparameters: {accuracy_filtered}\")\n",
    "print(\"Confusion Matrix with filtered important features:\")\n",
    "print(conf_matrix_filtered)\n",
    "print(\"Classification Report with filtered important features:\")\n",
    "print(class_report_filtered)\n",
    "\n",
    "# Plot the decision tree with the filtered important features and optimized parameters\n",
    "plt.figure(figsize=(30, 20))\n",
    "plot_tree(best_dt_classifier, feature_names=important_features_filtered, class_names=['Not Exited', 'Exited'], filled=True, rounded=True)\n",
    "plt.title(\"Decision Tree Visualization with Filtered Important Features (Optimized Hyperparameters)\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1:\n",
    "    # explore logistic regression and ensemble models like Random Forests and Gradient Boosting Machines (GBMs). \n",
    "    # Use these models to predict customer churn and compare their performance to each other.\n",
    "# Evaluate the performance of your models using ROC/AUC, precision, and recall, and visualise these metrics for easier interpretation. \n",
    "# Check for signs of over- or underfitting and data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "# Now it’s time to improve your models. \n",
    "    # Apply hyperparameter tuning to optimise the parameters of your models. \n",
    "# Experiment with feature engineering techniques to create new features from the existing data. \n",
    "# Consider if data quality enhancements or sampling techniques could help improve your model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3\n",
    "# Focus on maintaining the quality of your model. \n",
    "# Outline an approach for monitoring your model's performance over time and detect any drift in the underlying data. Also, start thinking about how to communicate your findings.\n",
    "# Create visualisations that clearly and effectively communicate your model's performance and the key factors contributing to customer churn. Save these to your Python notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: Model Monitoring\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = df_encoded.drop('Exited', axis=1)  # Features\n",
    "y = df_encoded['Exited']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature variables (for models like DecisionTree, standardization is not mandatory, but let's do it for consistency)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a basic Decision Tree Classifier\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Function to evaluate the model's performance on new data\n",
    "def evaluate_model(model, X_new, y_true):\n",
    "    # Predict the target for the new data\n",
    "    y_pred = model.predict(X_new)\n",
    "    y_proba = model.predict_proba(X_new)[:, 1]  # Probabilities for ROC-AUC\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_true, y_proba)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Function to monitor performance over time\n",
    "def monitor_performance(model, X_new, y_true, performance_log='model_performance_log.csv'):\n",
    "    # Get the current date and time\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Evaluate the model on the new data\n",
    "    metrics = evaluate_model(model, X_new, y_true)\n",
    "    \n",
    "    # Append the metrics to a DataFrame (for logging)\n",
    "    df_metrics = pd.DataFrame([metrics], index=[timestamp])\n",
    "    \n",
    "    # Check if the log file exists, if not, create it\n",
    "    try:\n",
    "        performance_log_df = pd.read_csv(performance_log, index_col=0)\n",
    "        # Append the new metrics\n",
    "        performance_log_df = pd.concat([performance_log_df, df_metrics])\n",
    "    except FileNotFoundError:\n",
    "        # If no log exists, start a new one\n",
    "        performance_log_df = df_metrics\n",
    "    \n",
    "    # Save the updated log back to the file\n",
    "    performance_log_df.to_csv(performance_log)\n",
    "    \n",
    "    print(f\"Metrics logged at {timestamp}:\")\n",
    "    print(df_metrics)\n",
    "    \n",
    "    return performance_log_df\n",
    "\n",
    "# Function to plot performance metrics over time\n",
    "def plot_performance_over_time(performance_log='model_performance_log.csv'):\n",
    "    # Load the performance log\n",
    "    performance_log_df = pd.read_csv(performance_log, index_col=0)\n",
    "    \n",
    "    # Plot the performance metrics\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for metric in performance_log_df.columns:\n",
    "        plt.plot(performance_log_df.index, performance_log_df[metric], label=metric)\n",
    "    \n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('Performance Metrics')\n",
    "    plt.title('Model Performance Over Time')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'model' is your trained classifier and X_new, y_true are new data\n",
    "\n",
    "# Monitor performance with new data (X_test_scaled and y_test)\n",
    "performance_log_df = monitor_performance(model, X_test_scaled, y_test)\n",
    "\n",
    "# Plot performance over time\n",
    "plot_performance_over_time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
